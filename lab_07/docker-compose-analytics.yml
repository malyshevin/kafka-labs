version: '3'
services:
  spark-master:
    image: bitnami/spark:3.5.4
    container_name: spark-master
    ports:
      - "7077:7077"  # Порт для подключения Executors
      - "8085:8080"  # HTTP-порт для Web UI Apache Spark master
    environment:
      SPARK_MODE: master
    networks:
      - lab_07_v2_default

  spark-worker:
    image: bitnami/spark:3.5.4
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8086:8081"  # HTTP-порт для Web UI Apache Spark worker
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
    networks:
      - lab_07_v2_default

  hadoop-namenode:
    image: apache/hadoop:3.4.1
    container_name: hadoop-namenode
    hostname: hadoop-namenode
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"   # Ограничение использования CPU
          memory: "2g"  # Ограничение использования RAM
    shm_size: 10G
    ports:
      - "9870:9870"  # HTTP-порт для Web UI HDFS NameNode
      - "9000:9000"  # RPC порт для запросов к NameNode
    volumes:
      - ./config/hdfs/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs/config/hdfs-site-namenode.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./config/hdfs/namenode_entrypoint.sh:/namenode_entrypoint.sh
    entrypoint: ["/bin/bash", "/namenode_entrypoint.sh"]
    command: ["hdfs", "namenode"]
    networks:
      - lab_07_v2_default

  hadoop-datanode-1:
    image: apache/hadoop:3.4.1
    container_name: hadoop-datanode-1
    hostname: hadoop-datanode-1
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"   # Ограничение использования CPU
          memory: "2g"  # Ограничение использования RAM
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9864:9864"  # HTTP-порт для Web UI DataNode №1
      - "9970:9970"  # RPC порт для запросов от NameNode
    volumes:
      - ./config/hdfs/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs/config/hdfs-site-datanode-1.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./config/hdfs/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - lab_07_v2_default

  hadoop-datanode-2:
    image: apache/hadoop:3.4.1
    container_name: hadoop-datanode-2
    hostname: hadoop-datanode-2
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"   # Ограничение использования CPU
          memory: "2g"  # Ограничение использования RAM
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9865:9865"  # HTTP-порт для Web UI DataNode №2
      - "9971:9971"  # RPC порт для запросов от NameNode
    volumes:
      - ./config/hdfs/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs/config/hdfs-site-datanode-2.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./config/hdfs/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - lab_07_v2_default

  hadoop-datanode-3:
    image: apache/hadoop:3.4.1
    container_name: hadoop-datanode-3
    hostname: hadoop-datanode-3
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"   # Ограничение использования CPU
          memory: "2g"  # Ограничение использования RAM
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9866:9866"  # HTTP-порт для Web UI DataNode №3
      - "9972:9972"  # RPC порт для запросов от NameNode
    volumes:
      - ./config/hdfs/config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs/config/hdfs-site-datanode-3.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./config/hdfs/datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - lab_07_v2_default

  recommend_app:
    build: ./recommend_app
    container_name: recommend_app
    depends_on:
      - hadoop-namenode
    environment:
      ANALYTICS_KAFKA_BOOTSTRAP_SERVERS: "analytics-broker1:9092,analytics-broker2:9092,analytics-broker3:9092"
      SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      SSL_KEYSTORE_PASSWORD: changeit
      SSL_KEY_PASSWORD: changeit
    volumes:
      - ./ssl/hdfs/:/app/ssl/hdfs/
      - ./ssl/ca/ca.crt:/app/ssl/ca.crt
    networks:
      - lab_07_v2_default

networks:
  lab_07_v2_default:
    external: true
